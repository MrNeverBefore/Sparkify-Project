{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparkify Project Workspace\n",
    "This workspace contains a tiny subset (128MB) of the full dataset available (12GB). Feel free to use this workspace to build your project, or to explore a smaller subset with Spark before deploying your cluster on the cloud. Instructions for setting up your Spark cluster is included in the last lesson of the Extracurricular Spark Course content.\n",
    "\n",
    "You can follow the steps below to guide your data analysis and model building portion of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-65d5905f15fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0misnan\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwhen\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconcat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexplode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mudf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0misnull\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mIntegerType\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession;\n",
    "from pyspark.sql.functions import isnan,count,when,col, concat, desc, explode, lit, min, max, split, udf, isnull;\n",
    "from pyspark.sql.types import IntegerType;\n",
    "\n",
    "from pyspark.ml.feature import RegexTokenizer, CountVectorizer,IDF, StringIndexer,VectorAssembler, Normalizer, StandardScaler;\n",
    "from pyspark.ml import Pipeline;\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier;\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator;\n",
    "\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import sum as Fsum\n",
    "\n",
    "import re;\n",
    "import datetime;\n",
    "import matplotlib.pyplot as plt;\n",
    "import pandas as pd;\n",
    "import seaborn as sns;\n",
    "import numpy as np;\n",
    "from itertools import cycle, islice;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Spark session\n",
    "spark = SparkSession\\\n",
    "                    .builder\\\n",
    "                    .master('local')\\\n",
    "                    .appName(\"Sparkify\")\\\n",
    "                    .getOrCreate();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Clean Dataset\n",
    "In this workspace, the mini-dataset file is `mini_sparkify_event_data.json`. Load and clean the dataset, checking for invalid or missing data - for example, records without userids or sessionids. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data \"mini_sparkify_event_data.json\"\n",
    "df = spark.read.json('mini_sparkify_event_data.json');\n",
    "\n",
    "#see top records in dataset\n",
    "df.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.take(5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets look at shema of data :\n",
    "df.printSchema();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of  Rows in the dataframe:{}\".format(df.count()));\n",
    "print(\"Number of  columns in the dataframe:{}\".format(len(df.columns)));\n",
    "print(\"columns Present in data set in the dataframe{}\".format(df.columns));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discribing all the columns in dataframe\n",
    "df.describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.toPandas().isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.toPandas().isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NAs there is no null values in columns in userId and sessionId\n",
    "df = df.dropna(how = 'any', subset = ['userId', 'sessionId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect 'userId' column\n",
    "df.select('userId').dropDuplicates().sort('userId').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# drop empty strings\n",
    "df = df.filter(df['userId'] != '')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "When you're working with the full dataset, perform EDA by loading a small subset of the data and doing basic manipulations within Spark. In this workspace, you are already provided a small subset of data you can explore.\n",
    "\n",
    "### Define Churn\n",
    "\n",
    "Once you've done some preliminary analysis, create a column `Churn` to use as the label for your model. I suggest using the `Cancellation Confirmation` events to define your churn, which happen for both paid and free users. As a bonus task, you can also look into the `Downgrade` events.\n",
    "\n",
    "### Explore Data\n",
    "Once you've defined churn, perform some exploratory data analysis to observe the behavior for users who stayed vs users who churned. You can start by exploring aggregates on these two groups of users, observing how much of a specific action they experienced per a certain time unit or number of songs played."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select('page','UserId').groupby('page').agg({'page':'count'}).select('page','count(page)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Churn is a label for user who cancelled\n",
    "# Define a flag function\n",
    "flag_cancelation_event = udf(lambda x: 1 if x == \"Cancellation Confirmation\" else 0, IntegerType())\n",
    "# apply to the dataframe\n",
    "df = df.withColumn(\"churn\", flag_cancelation_event(\"page\"))\n",
    "#Define window bounds\n",
    "windowval = Window.partitionBy(\"userId\").rangeBetween(Window.unboundedPreceding, Window.unboundedFollowing)\n",
    "# Applying the window\n",
    "df = df.withColumn(\"churn\", Fsum(\"churn\").over(windowval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a temp view from dataframe df,so that we can use sparkSQL for quick easy analysis\n",
    "df.createOrReplaceTempView('data');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "          SELECT\n",
    "              churn,\n",
    "              count(distinct userId)\n",
    "            FROM\n",
    "                data\n",
    "            GROUP BY\n",
    "                churn\n",
    "            \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('SELECT COUNT(DISTINCT userId) As count_of_Uniq_users  FROM data').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_with_downgrade = spark.sql(\"select distinct userId from data where page = 'Submit Downgrade'\")\n",
    "user_with_downgrade = user_with_downgrade.toPandas()['userId'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_sub_downgrade = udf(lambda user: 1 if user in user_with_downgrade else 0, IntegerType())\n",
    "spark.udf.register('has_sub_downgrade', has_sub_downgrade)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = spark.sql(\"\"\"\n",
    "    SELECT * ,\n",
    "        has_sub_downgrade(userId) as hasSubDowngrade\n",
    "    FROM\n",
    "        data\n",
    "    \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_1.createOrReplaceTempView('data_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_downgrade = spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        DISTINCT userId,\n",
    "        hasSubDowngrade,\n",
    "        churn\n",
    "    FROM\n",
    "        data_1\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_downgrade.createOrReplaceTempView('feature_downgrade_tbl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select churn, sum(hasSubDowngrade)/count(distinct userId) As difference_in_submitting_downgrade from feature_downgrade_tbl group by churn\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "Once you've familiarized yourself with the data, build out the features you find promising to train your model on. To work with the full dataset, you can follow the following steps.\n",
    "- Write a script to extract the necessary features from the smaller subset of data\n",
    "- Ensure that your script is scalable, using the best practices discussed in Lesson 3\n",
    "- Try your script on the full data set, debugging your script if necessary\n",
    "\n",
    "If you are working in the classroom workspace, you can just extract features based on the small subset of data contained here. Be sure to transfer over this work to the larger dataset when you work on your Spark cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark.sql(\"SELECT churn,count(1)/count(DISTINCT userId) AS Freinds FROM data_1\\\n",
    "            WHERE page = 'Add Friend' GROUP BY churn\").show();\n",
    "Freinds_vs=spark.sql(\"SELECT churn,count(1)/count(DISTINCT userId) AS Freinds FROM data_1\\\n",
    "            WHERE page = 'Add Friend' GROUP BY churn\").toPandas();\n",
    "\n",
    "feature_friends = spark.sql(\"SELECT DISTINCT(userId),count(1) AS Friends FROM data_1\\\n",
    "        WHERE page = 'Add Friend' GROUP BY userId\");\n",
    "\n",
    "feature_friends.createOrReplaceTempView('feature_friends');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.title(\"Distribution of feature_friends vs Target Churn\");\n",
    "sns.barplot(x=\"churn\", y=\"Freinds\", data=Freinds_vs);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT churn,count(1)/count(DISTINCT userId)  AS Playlist FROM data_1\\\n",
    "                        WHERE page ='Add to Playlist' GROUP BY churn\").show();\n",
    "\n",
    "Playlist_vs=spark.sql(\"SELECT churn,count(1)/count(DISTINCT userId)  AS Playlist FROM data_1\\\n",
    "                        WHERE page ='Add to Playlist' GROUP BY churn\").toPandas();\n",
    "\n",
    "feature_Playlist=spark.sql(\"SELECT DISTINCT(userId),count(1)/count(DISTINCT userId) AS Playlist FROM data_1\\\n",
    "            WHERE page ='Add to Playlist' GROUP BY userId\");\n",
    "\n",
    "\n",
    "feature_Playlist.createOrReplaceTempView('feature_add_Playlist');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Distribution of feature_Playlist w.r.t Target Churn\");\n",
    "sns.barplot(x=\"churn\", y=\"Playlist\", data=Playlist_vs,palette=\"muted\");\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark.sql(\"SELECT churn,\\\n",
    "          sum(length)/count(distinct userId)  \\\n",
    "          AS usageTime FROM data_1\\\n",
    "          WHERE page = 'NextSong' GROUP BY  churn\").show();\n",
    "\n",
    "usage_time_vs=spark.sql(\"SELECT churn,sum(length)/count(distinct userId) AS usageTime FROM data_1\\\n",
    "                        WHERE page = 'NextSong' GROUP BY  churn\").toPandas();\n",
    "\n",
    "feature_usage_time=spark.sql(\"SELECT DISTINCT(userId),sum(nvl(length, 0)) AS usageTime FROM data_1\\\n",
    "                              WHERE page = 'NextSong' GROUP BY userId\");\n",
    "\n",
    "feature_usage_time.createOrReplaceTempView('feature_usage_time');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Distribution of feature_usage_time vs Target Churn\");\n",
    "sns.barplot(x=\"churn\", y=\"usageTime\", data=usage_time_vs,palette=\"muted\");\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT churn,count(1)/count(DISTINCT userId) \\\n",
    "    AS Downgrade FROM data_1 \\\n",
    "    WHERE page ='Downgrade' GROUP BY churn\").show();\n",
    "Downgrade_vs=spark.sql(\"SELECT churn,count(1)/count(DISTINCT userId) \\\n",
    "    AS Downgrade FROM data_1 \\\n",
    "    WHERE page ='Downgrade' GROUP BY churn\").toPandas();\n",
    "\n",
    "feature_Downgrade=spark.sql(\"SELECT DISTINCT(userId),count(1)/count(DISTINCT userId) AS Downgrade FROM data_1\\\n",
    "                        WHERE page ='Downgrade' GROUP BY userId\");\n",
    "\n",
    "feature_Downgrade.createOrReplaceTempView('feature_Downgrade');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Distribution of feature_Downgrade vs Target Churn\");\n",
    "sns.barplot(x=\"churn\", y=\"Downgrade\", data=Downgrade_vs,palette=\"muted\");\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT churn,gender,count(1)/count(DISTINCT userId) gender_cnt FROM data_1 GROUP BY churn,gender\").show();\n",
    "\n",
    "gender_vs=spark.sql(\"SELECT churn,gender,count(1)/count(DISTINCT userId) gender_cnt FROM data_1 GROUP BY churn,gender\").toPandas();\n",
    "\n",
    "feature_gender = spark.sql(\"SELECT DISTINCT(userId),CASE when gender='M' then 1 \\\n",
    "                            when gender='F' then 0 else 2 END AS gender_dummy FROM data_1\");\n",
    " \n",
    "feature_gender.createOrReplaceTempView('feature_gender');\n",
    "spark.sql(\"select gender_dummy,count(DISTINCT(userId)) from feature_gender group by gender_dummy\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-b1726acc84b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Distribution of feature_gender vs Target Churn\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"churn\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"gender_cnt\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gender'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgender_vs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.title(\"Distribution of feature_gender vs Target Churn\");\n",
    "sns.barplot(x=\"churn\", y=\"gender_cnt\", hue='gender',data=gender_vs);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT churn,avg(distinct sessionId) \\\n",
    "    AS avg_no_sessions FROM data_1 group by churn\").show();\n",
    "\n",
    "avg_no_sessions_vs=spark.sql(\"SELECT churn,avg(distinct sessionId) AS avg_no_sessions \\\n",
    "                             FROM data_1 group by churn\").toPandas();\n",
    "\n",
    "feature_avg_no_sessions = spark.sql(\"SELECT DISTINCT(userId),avg(distinct sessionId) AS avg_no_sessions FROM data_1 group\\\n",
    "                            by userId\");\n",
    "\n",
    "feature_avg_no_sessions.createOrReplaceTempView('feature_avg_no_sessions');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.title(\"Distribution of feature_avg_no_sessions w.r.t Target [Churn]\");\n",
    "sns.barplot(x=\"churn\", y=\"avg_no_sessions\", data=avg_no_sessions_vs);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT churn,count(1)/count(DISTINCT userId) AS level_paid \\\n",
    "    FROM data_1 WHERE level = 'paid' \\\n",
    "    GROUP BY churn\").show();\n",
    "\n",
    "level_paid_vs=spark.sql(\"SELECT churn,count(1)/count(DISTINCT userId) AS level_paid \\\n",
    "    FROM data_1 WHERE level = 'paid' GROUP BY churn\").toPandas();\n",
    "\n",
    "feature_level_paid = spark.sql(\"SELECT DISTINCT(userId),count(1)/count(DISTINCT userId) AS level_paid FROM data_1\\\n",
    "                    WHERE level = 'paid' GROUP BY userId\");\n",
    "\n",
    "feature_level_paid.createOrReplaceTempView('feature_level_paid');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.title(\"Distribution of feature_level_paid w.r.t Target [Churn]\");\n",
    "sns.barplot(x=\"churn\", y=\"level_paid\", data=level_paid_vs,palette=\"muted\");\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT churn,count(1)/count(DISTINCT userId) AS level_free FROM data_1 WHERE level = 'free' GROUP BY churn\").show();\n",
    "\n",
    "level_free_vs=spark.sql(\"SELECT churn,count(1)/count(DISTINCT userId) AS level_free FROM data_1 WHERE level = 'free' GROUP BY churn\").toPandas();\n",
    "\n",
    "feature_level_free = spark.sql(\"SELECT DISTINCT(userId),count(1)/count(DISTINCT userId) AS level_free FROM data_1\\\n",
    "                    WHERE level = 'free' GROUP BY userId\");\n",
    "\n",
    "feature_level_free.createOrReplaceTempView('feature_level_free');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.title(\"Distribution of feature_level_free w.r.t Target [Churn]\");\n",
    "sns.barplot(x=\"churn\", y=\"level_free\", data=level_free_vs);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT churn,count(1)/count(DISTINCT userId) as n_ThumpsUp \\\n",
    "    FROM data_1 WHERE page = 'Thumbs Up' GROUP BY churn\").show()\n",
    "\n",
    "feature_thumps_up_vs= spark.sql(\"SELECT churn, count(1)/count(DISTINCT userId) as n_ThumpsUp \\\n",
    "    FROM data_1 WHERE page = 'Thumbs Up' GROUP BY churn\").toPandas()\n",
    "\n",
    "feature_thumps_up = spark.sql(\"SELECT DISTINCT(userId),count(1)/count(DISTINCT userId) AS n_Thumpsup \\\n",
    "    FROM data_1 WHERE page = 'Thumbs Up' GROUP BY userId\");\n",
    "\n",
    "\n",
    "\n",
    "feature_thumps_up.createOrReplaceTempView('feature_thumps_up');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.title(\"Distribution of feture Thumbs Up vs Target [Churn]\");\n",
    "sns.barplot(x=\"churn\", y=\"n_ThumpsUp\", data=feature_thumps_up_vs);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT churn,count(1)/count(DISTINCT userId) As help FROM data_1 WHERE page ='Help' GROUP BY churn\").show();\n",
    "help_vs=spark.sql(\"SELECT churn,count(1)/count(DISTINCT userId) As help FROM data_1 WHERE page ='Help' GROUP BY churn\").toPandas();\n",
    "feature_help=spark.sql(\"SELECT DISTINCT(userId),count(1)/count(DISTINCT userId) AS help FROM data_1\\\n",
    "                        WHERE page ='Help' GROUP BY userId\");\n",
    "\n",
    "feature_help.createOrReplaceTempView('feature_help');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Distribution of feature_help vs Target [Churn]\");\n",
    "sns.barplot(x=\"churn\", y=\"help\", data=help_vs);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_table = spark.sql(\"SELECT a.userId,b.Playlist,c.usageTime,\\\n",
    "                            d.Downgrade,e.help,f.friends,g.level_paid,k.n_Thumpsup,h.level_free,\\\n",
    "                            i.avg_no_sessions,j.gender_dummy,a.churn as label FROM data_1 as a\\\n",
    "                            LEFT OUTER JOIN feature_add_Playlist as b\\\n",
    "                            ON a.userId=b.userId \\\n",
    "                            LEFT OUTER JOIN feature_usage_time as c\\\n",
    "                            ON b.userId = c.userId\\\n",
    "                            LEFT OUTER JOIN feature_Downgrade as d\\\n",
    "                            ON c.userId=d.userId\\\n",
    "                            LEFT OUTER JOIN feature_help as e\\\n",
    "                            ON d.userId=e.userId\\\n",
    "                            LEFT OUTER JOIN feature_friends as f\\\n",
    "                            ON e.userId=f.userId\\\n",
    "                            LEFT OUTER JOIN feature_level_paid as g\\\n",
    "                            ON f.userId=g.userId\\\n",
    "                            LEFT OUTER JOIN feature_level_free as h\\\n",
    "                            ON g.userId=h.userId\\\n",
    "                            LEFT OUTER JOIN feature_avg_no_sessions as i\\\n",
    "                            ON h.userId=i.userId\\\n",
    "                            LEFT OUTER JOIN feature_gender j\\\n",
    "                            on i.userId=j.userId\\\n",
    "                            LEFT OUTER JOIN feature_thumps_up k\\\n",
    "                            on j.userId=k.userId\");\n",
    "\n",
    "feature_table.createOrReplaceTempView('feature_table')\n",
    "\n",
    "#check distribution of class looks fine or not?\n",
    "spark.sql(\"select label,count(distinct userId) as Class_dist from feature_table group by label\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "feature_table.toPandas().isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check in case if any Null values will be present.\n",
    "#impute them with zero(0) for all except gender because we it will wrong imputation so we will keep value as 2 for all null treating it differently in model.\n",
    "\n",
    "selected_feature_table = spark.sql(\"SELECT nvl(userId,0) as userId,nvl(Playlist,0) as Playlist,nvl(usageTime,0) as usageTime,\\\n",
    "        nvl(Downgrade,0) as Downgrade,nvl(help,0) as help,nvl(friends,0) as friends,nvl(level_paid,0) as level_paid,\\\n",
    "        nvl(level_free,0) as level_free,nvl(avg_no_sessions,0) as avg_no_sessions,nvl(gender_dummy,2) as gender, nvl(n_Thumpsup,0) as n_Thumpsup, nvl(label,0) as label  FROM\\\n",
    "        feature_table\");\n",
    "\n",
    "#crate master_feature_table\n",
    "selected_feature_table.createOrReplaceTempView('selected_feature_table');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_feature_table.toPandas().isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,12))\n",
    "plt.title('Correlation between all the selected columns', y=1.05, size=15)\n",
    "sns.heatmap(selected_feature_table.toPandas().corr(),linewidths=0.1,vmax=1.0, \n",
    "            square=True, cmap=plt.cm.inferno, linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "Split the full dataset into train, test, and validation sets. Test out several of the machine learning methods you learned. Evaluate the accuracy of the various models, tuning parameters as necessary. Determine your winning model based on test accuracy and report results on the validation set. Since the churned users are a fairly small subset, I suggest using F1 score as the metric to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create VectorAssembler to push data to ML models\n",
    "assembler = VectorAssembler(inputCols=[\"Playlist\",\"usageTime\",\"Downgrade\",\"help\",\\\n",
    "                                       \"friends\",\"level_paid\",\"level_free\",\"avg_no_sessions\",\"gender\",\"n_Thumpsup\"],\\\n",
    "                            outputCol=\"inputFeatures\")\n",
    "\n",
    "#Lets normalize data\n",
    "scaler = Normalizer(inputCol=\"inputFeatures\", outputCol=\"ScaledFeatures\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elasticNetParam corresponds to α and regParam corresponds to λ.\n",
    "model_lr = LogisticRegression(featuresCol=\"ScaledFeatures\", labelCol=\"label\", maxIter=10, regParam=0.01)\n",
    "model_rf = RandomForestClassifier(featuresCol=\"ScaledFeatures\", labelCol=\"label\")\n",
    "model_gbt = GBTClassifier(featuresCol=\"ScaledFeatures\", labelCol=\"label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Pipeline\n",
    "pipeline_lr = Pipeline(stages=[assembler, scaler, model_lr]);\n",
    "pipeline_rf = Pipeline(stages=[assembler, scaler, model_rf]);\n",
    "pipeline_gbt = Pipeline(stages=[assembler, scaler, model_gbt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spilt data for Train and test \n",
    "training, test = selected_feature_table.randomSplit([0.8, 0.2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training.toPandas().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model\n",
    "import time\n",
    "\n",
    "start_time= time.time()\n",
    "\n",
    "model_lr_fitted = pipeline_lr.fit(training);\n",
    "model_rf_fitted = pipeline_rf.fit(training);\n",
    "model_gbt_fitted = pipeline_gbt.fit(training)\n",
    "\n",
    "end_time= time.time()\n",
    "\n",
    "print(\"Total exicute time:{}\".format(end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function which will calcualte Accuracy scores:\n",
    "def model_performance_accuracy(model, test_data, metric = 'accuracy'):\n",
    "    \"\"\" Calculate Model Scores using f1 metric \n",
    "        Input: \n",
    "            model- trained model or pipeline object\n",
    "            metric- the metric used to measure performance\n",
    "            data - data on which performance measurement should be done\n",
    "        Output:\n",
    "            score\n",
    "    \"\"\"\n",
    "    evaluator = MulticlassClassificationEvaluator(metricName = metric)\n",
    "    prediction_result = model.transform(test_data)\n",
    "    # find f1 score\n",
    "    score = evaluator.evaluate(prediction_result)\n",
    "    #return score\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print both Model Testing F1-Score\n",
    "print(\"Logistic Regression Classifier Accuracy:{}\".format(model_performance_accuracy(model_lr_fitted, test)));\n",
    "print(\"Random Forest  Classifier Accuracy:{}\".format(model_performance_accuracy(model_rf_fitted, test)));\n",
    "print(\"GBTClassifier  Classifier Accuracy:{}\".format(model_performance_accuracy(model_gbt_fitted, test)));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function which will calcualte f1 scores:\n",
    "def model_performance(model, test_data, metric = 'f1'):\n",
    "    \"\"\" Calculate Model Scores using f1 metric \n",
    "        Input: \n",
    "            model- trained model or pipeline object\n",
    "            metric- the metric used to measure performance\n",
    "            data - data on which performance measurement should be done\n",
    "        Output:\n",
    "            score\n",
    "    \"\"\"\n",
    "    evaluator = MulticlassClassificationEvaluator(metricName = metric)\n",
    "    prediction_result = model.transform(test_data)\n",
    "    # find f1 score\n",
    "    score = evaluator.evaluate(prediction_result)\n",
    "    #return score\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print both Model Testing F1-Score\n",
    "print(\"Logistic Regression Classifier F1-Score:{}\".format(model_performance(model_lr_fitted, test)));\n",
    "print(\"Random Forest  Classifier F1-Score:{}\".format(model_performance(model_rf_fitted, test)));\n",
    "print(\"GBTClassifier  Classifier F1-Score:{}\".format(model_performance(model_gbt_fitted, test)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A model is implemented to predict coustemer churn. Cleaned the rows with no userId and converted gender into binary form. For the model 10 featuers were built. Three predicting algorithm were tried which is logistic regression, Random Forest and GBTClassifier in which GBTClassifier is selcted as final model as its resultis better than other models. VectorAssembler is used to prepare and push the data to the model, which combines a given list of columns into a singel vector column. F1 score is used as the metric optimize.\n",
    "\n",
    "\n",
    "<h3>Improvement</h3>\n",
    "The features can be improved a lot after considering more factors, adding more domain knowledges and expertise. Although the volume of data may required tools such as spark to analyze, but we can use more data to have better results as the user base grow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Steps\n",
    "Clean up your code, adding comments and renaming variables to make the code easier to read and maintain. Refer to the Spark Project Overview page and Data Scientist Capstone Project Rubric to make sure you are including all components of the capstone project and meet all expectations. Remember, this includes thorough documentation in a README file in a Github repository, as well as a web app or blog post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
